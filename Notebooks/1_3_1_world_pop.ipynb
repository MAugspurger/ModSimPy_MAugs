{"cells":[{"cell_type":"markdown","id":"wicked-mozambique","metadata":{"id":"wicked-mozambique"},"source":["# 1.3.1: World Population (Abstraction)\n","\n","<br>\n","\n","---"]},{"cell_type":"markdown","id":"imported-table","metadata":{"tags":[],"id":"imported-table"},"source":["*Modeling and Simulation in Python*\n","\n","Copyright 2021 Allen Downey, (License: [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/))\n","\n","Revised, Mike Augspurger (2021-present)\n","\n","<br>\n","\n","---\n"]},{"cell_type":"markdown","source":["In the previous chapter, we used a model to optimize the design of our bikeshare system.  In this chapter, we'll turn to the other purposes for modeling: explanation and prediction.  We're going to start with a set of data (world population growth since 1950) and try to build a model that matches the data.  In other words, we want to find the \"set of rules\" that can be used to generate a model that matches a given system.  \n","\n","<br>\n","\n","Thus the abstraction step for this process is less about choosing variables (as was the case for the falling penny and bikeshare) and more about defining relationships: the \"set of rules\" that defines the model.  Once we have defined the rules, we can use them to generate predictions for the next 50-100 years.\n","\n","<br>\n","\n","But we'll have to start by learning how to import data."],"metadata":{"id":"2N5MTyKy8OZX"},"id":"2N5MTyKy8OZX"},{"cell_type":"code","execution_count":null,"id":"electoral-turkey","metadata":{"tags":[],"id":"electoral-turkey","cellView":"form"},"outputs":[],"source":["#@title\n","# Import libraries\n","from os.path import basename, exists\n","from os import mkdir\n","\n","def download(url,folder):\n","    filename = folder + basename(url)\n","    if not exists(folder):\n","        mkdir(folder)\n","    # fetches the file at the given url if it is not already present\n","    if not exists(filename):\n","        from urllib.request import urlretrieve\n","        local, _ = urlretrieve(url, filename)\n","        print('Downloaded ' + local)\n","\n","download('https://github.com/MAugspurger/ModSimPy_MAugs/raw/main/Notebooks/'\n","        + 'ModSimPy_Functions/modsim.py', 'ModSimPy_Functions/')\n","\n","from ModSimPy_Functions.modsim import *\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"Jd0mObsy9Twl"},"id":"Jd0mObsy9Twl"},{"cell_type":"markdown","source":["## Importing Population Data into Jupyter\n","\n","First, we need some data.  This [Wikipedia article on world population](https://en.wikipedia.org/wiki/Estimates_of_historical_world_population) contains tables with estimates of world population from prehistory to the present, and projections for the future."],"metadata":{"id":"Z0etZjQA_cTH"},"id":"Z0etZjQA_cTH"},{"cell_type":"markdown","id":"acknowledged-bracelet","metadata":{"id":"acknowledged-bracelet"},"source":["We're going to use the Pandas library, which provides functions for\n","working with data, to read and import the data from the tables in the article. The function we'll use is `read_html`, which can read a web page or .html file and extract data from any tables it contains. At the top of the page, we imported Pandas and gave it the shorthand `pd`.  Now we can use it like this:"]},{"cell_type":"code","execution_count":null,"id":"instant-beverage","metadata":{"id":"instant-beverage"},"outputs":[],"source":["filename = 'https://github.com/MAugspurger/ModSimPy_MAugs/raw/main/Images_and_Data/Data/World_population_estimates.html'\n","# If you are using this notebook offline, you will need to upload this data\n","# from the Images_and_Data folder.  Comment out the line above, and uncomment the\n","# line below this one, and run this cell\n","# filename = '../Images_and_Data/Data/World_population_estimates.html'\n","\n","tables = pd.read_html(filename,\n","                   header=0, \n","                   index_col=0,\n","                   decimal='M')"]},{"cell_type":"markdown","id":"dried-immunology","metadata":{"id":"dried-immunology"},"source":["The arguments are:\n","\n","-   `filename`: The name of the file (including the directory)\n","    as a string (We're actually importing an .html file from my Github account rather than directly from the internet to avoid any problems with changes to the website).\n","\n","-   `header`: Indicates which row of each table should be considered the\n","    *header*, that is, the set of labels that identify the columns. In\n","    this case it is the first row (numbered 0).\n","\n","-   `index_col`: Indicates which column of each table should be\n","    considered the *index*, that is, the set of labels that identify\n","    the rows. In this case it is the first column, which contains the\n","    years.\n","\n","-   `decimal`: Normally this argument is used to indicate which\n","    character should be considered a decimal point, because some\n","    conventions use a period and some use a comma. In this case we are\n","    abusing the feature by treating `M` as a decimal point, which allows\n","    some of the estimates, which are expressed in millions, to be read\n","    as numbers.\n","\n","The result, which is assigned to `tables`, is a sequence that contains\n","one `DataFrame` for each table. A `DataFrame` is an object, defined by\n","Pandas, that represents tabular data.  We've used `DataFrame` before, to get a nice table-like output for our `Series`.  Now we'll use it for its central purpose, which is to hold multiple multi-columned tables, where each column is a `Series`.\n","\n","<br>\n","\n","Go ahead and open the Wikipedia page that is linked above.  You can see that there are multiple tables.  `read_html` imported and processed all of these tables, and stores them as different 'sheets' in the `DataFrame` (just like with a spreadsheet program).\n","\n","<br>\n","\n","To select the table we want from `tables`, we can use the bracket operator\n","like this.  We want the third table (i.e. the one with index number 2):"]},{"cell_type":"code","execution_count":null,"id":"driving-wrapping","metadata":{"id":"driving-wrapping"},"outputs":[],"source":["table2 = tables[2]"]},{"cell_type":"markdown","id":"simplified-convert","metadata":{"id":"simplified-convert"},"source":["This line selects the third table (numbered 2), which contains\n","population estimates from 1950 to 2016.  We can use the class function `head` to display the first few lines of the table.  If you are interested, here's the information about [the many class functions](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) that are attributes of a `DataFrame`."]},{"cell_type":"code","execution_count":null,"id":"running-alcohol","metadata":{"id":"running-alcohol"},"outputs":[],"source":["table2.head()"]},{"cell_type":"markdown","id":"valid-editing","metadata":{"id":"valid-editing"},"source":["A couple things to notice:\n","\n","* The first column, which is labeled `Year`, is special.  It is the *index* for this `DataFrame`, which means it contains the labels for the rows.  \n","* Some of the values use scientific notation; for example, `2.544000e+09` is shorthand for $2.544 \\cdot 10^9$ or 2.544 billion.\n","* `NaN` is a special value that indicates missing data (it stands for \"Not a Number\").\n","* Notice the little \"magic wand\" icon next to the table: Colab allows us to interact with the table directly in Jupyter if we wanted to (we won't do that now, but feel free to click the icon and see what it does--it will not change the underlying data that we've imported)."]},{"cell_type":"markdown","id":"plastic-senate","metadata":{"id":"plastic-senate"},"source":["The column labels (such as \"United States Census Bureau (2017)[28]\") are long strings, which makes them hard to work with.  We can replace them with shorter strings like this:"]},{"cell_type":"code","execution_count":null,"id":"engaging-regular","metadata":{"id":"engaging-regular"},"outputs":[],"source":["table2.columns = ['census', 'prb', 'un', 'maddison', \n","                  'hyde', 'tanton', 'biraben', 'mj', \n","                  'thomlinson', 'durand', 'clark']"]},{"cell_type":"markdown","id":"communist-crowd","metadata":{"id":"communist-crowd"},"source":["Now we can select a column from the `DataFrame` using the dot operator.  Here are the estimates from the United States Census Bureau:"]},{"cell_type":"code","execution_count":null,"id":"amended-negative","metadata":{"id":"amended-negative"},"outputs":[],"source":["census = table2.census / 1e9"]},{"cell_type":"markdown","id":"absent-heart","metadata":{"id":"absent-heart"},"source":["The result is a Pandas `Series`, which we are familiar with.  The number `1e9` is a shorter way to write `1000000000` or one billion.\n","When we divide a `Series` by a number, it divides all of the elements of the `Series`.\n","From here on, we'll express population estimates in terms of billions.\n","\n","<br>\n","\n","We can use `tail` to see the last few elements of the `Series`:"]},{"cell_type":"code","execution_count":null,"id":"graduate-specialist","metadata":{"id":"graduate-specialist"},"outputs":[],"source":["census.tail()"]},{"cell_type":"markdown","id":"brilliant-brook","metadata":{"id":"brilliant-brook"},"source":["The left column is the *index* of the `Series`; in this example it contains the dates.\n","The right column contains the *values*, which are population estimates.\n","In 2016 the world population was about 7.3 billion.\n","\n","<br>\n","\n","Here are the estimates from the United Nations\n","Department of Economic and Social Affairs (U.N. DESA):"]},{"cell_type":"code","execution_count":null,"id":"linear-admission","metadata":{"id":"linear-admission"},"outputs":[],"source":["un = table2.un / 1e9\n","un.tail()"]},{"cell_type":"markdown","id":"mental-sussex","metadata":{"id":"mental-sussex"},"source":["The most recent estimate we have from the U.N. is for 2015, so the value for 2016 is `NaN`.\n","\n","<br>\n","\n","Now we can plot the estimates like this:"]},{"cell_type":"code","execution_count":null,"id":"ordered-garage","metadata":{"id":"ordered-garage"},"outputs":[],"source":["def plot_estimates():\n","    census.plot(style=':', label='US Census',legend=True)\n","    un.plot(style='--', label='UN DESA',xlabel='Year', \n","             ylabel='World population (billion)',\n","            title='World population Estimates',\n","           legend=True); "]},{"cell_type":"markdown","id":"invisible-mouse","metadata":{"id":"invisible-mouse"},"source":["And here's what it looks like."]},{"cell_type":"code","execution_count":null,"id":"periodic-weekend","metadata":{"id":"periodic-weekend"},"outputs":[],"source":["plot_estimates()"]},{"cell_type":"markdown","id":"labeled-magic","metadata":{"id":"labeled-magic"},"source":["The lines overlap almost completely, but the most recent estimates diverge slightly.\n","\n","<br>\n","\n","‚úÖ Active Reading: Notice in the definition for the `plot_estimates` function that `.plot` is called twice to make a single graph.  Go back and write the documentation (docstring and a comment line for each line) for the function\n","\n","<br>\n","\n","---"]},{"cell_type":"markdown","source":["## Using mathematical tools to understand data\n","\n","Now that we've imported the data, we want to try to understand it: we need this understanding in order to decide what kind of model we'll use to predict future growth.  In other words, we need to know the 'rules' that population growth follows."],"metadata":{"id":"4cL_eLdkJ7WC"},"id":"4cL_eLdkJ7WC"},{"cell_type":"markdown","id":"vietnamese-excuse","metadata":{"id":"vietnamese-excuse"},"source":["### Curve fitting as modeling\n","\n","Curve fitting is one way that we can understand the 'rules' that a system is following.  When we fit a curve, we are trying to determine the mathematical function (that is, the 'rule') that best represents the data.\n","\n","<br>\n","\n","Sometimes when we fit a curve, we know what the curve should look like: that is, we know how that particular system behaves.  For instance, if we plot the kinematic equation $x = vt$, which says that the distance traveled $x$ is equal to the velocity times the times, we would expect a linear plot.  Here's a quick visualization, for instance, of a 'time vs. distance' plot for a drive from Augie to Chicago along with a linear fitted curve:"]},{"cell_type":"code","source":["#chicago_trip = pd.Series(dict(0=0,30=36,60=74,90=104,120=150,141=167),name=\"Trip to Chicago\")\n","chicago_trip = pd.Series({'0':0,'30':38,'60':66,'90':104,'120':150,'150':177},name=\"Trip to Chicago\")\n","linear_fit = pd.Series({'0':0,'30':35.5,'60':71.0,'90':106.5,'120':142,'150':177.5})\n","\n","linear_fit.plot(label='Fitted Curve',legend='True')\n","chicago_trip.plot(style='.',xlabel='time (minutes)', \n","        ylabel='distance (miles)', label='Data Points',legend='True'); "],"metadata":{"id":"iiRMGmk8L_dS"},"id":"iiRMGmk8L_dS","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In this example, we already know the 'rule' that the system follows: it is the equation $x=vt$.  In other situations, though, like world population, we don't know the rules.  So we use curve fitting to help us find the rules: if we can find a curve that matches the data, then we start to better understand the system!\n","\n","<br>\n","\n","As usual, we'll start simple and add complexity as we go.  Although there is some curvature in the plotted estimates, it looks like world population growth has been close to linear since 1960 or so.  To fit the model to the data, we'll compute the average annual growth\n","from 1950 to 2016. Since the UN and Census data are so close, we'll use the Census data.\n","\n","<br>\n","\n","We can select a value from a `Series` using the bracket operator:"],"metadata":{"id":"g9I-ScoXUZgr"},"id":"g9I-ScoXUZgr"},{"cell_type":"code","execution_count":null,"id":"undefined-sauce","metadata":{"id":"undefined-sauce"},"outputs":[],"source":["census[1950]"]},{"cell_type":"markdown","id":"precise-correlation","metadata":{"id":"precise-correlation"},"source":["So we can get the total growth during the interval like this:"]},{"cell_type":"code","execution_count":null,"id":"postal-debate","metadata":{"id":"postal-debate"},"outputs":[],"source":["total_growth = census[2016] - census[1950]\n","total_growth"]},{"cell_type":"markdown","id":"dutch-sample","metadata":{"id":"dutch-sample"},"source":["In this example, the labels `2016` and `1950` are part of the data, so it\n","would be better not to make them part of the program. \n","Putting values like these in the program is called *hard coding*; it is considered bad practice because if the data change in the future, we have to change the program.\n","\n","<br>\n","\n","It would be better to get the labels from the `Series`.\n","We can do that by selecting the index from `census` and then selecting the first element."]},{"cell_type":"code","execution_count":null,"id":"functional-trick","metadata":{"id":"functional-trick"},"outputs":[],"source":["t_0 = census.index[0]\n","t_0"]},{"cell_type":"markdown","id":"empty-siemens","metadata":{"id":"empty-siemens"},"source":["So `t_0` is the label of the first element, which is 1950.\n","We can get the label of the last element like this."]},{"cell_type":"code","execution_count":null,"id":"acoustic-south","metadata":{"id":"acoustic-south"},"outputs":[],"source":["t_end = census.index[-1]\n","t_end"]},{"cell_type":"markdown","id":"express-metallic","metadata":{"id":"express-metallic"},"source":["The value `-1` indicates the last element; `-2` indicates the second to last element, and so on.  The difference between `t_0` and `t_end` is the elapsed time between them."]},{"cell_type":"code","execution_count":null,"id":"planned-remains","metadata":{"id":"planned-remains"},"outputs":[],"source":["elapsed_time = t_end - t_0\n","elapsed_time"]},{"cell_type":"markdown","id":"bridal-royal","metadata":{"id":"bridal-royal"},"source":["Now we can use `t_0` and `t_end` to select the population at the beginning and end of the interval."]},{"cell_type":"code","execution_count":null,"id":"quarterly-aggregate","metadata":{"id":"quarterly-aggregate"},"outputs":[],"source":["p_0 = census[t_0]\n","p_end = census[t_end]"]},{"cell_type":"markdown","id":"driven-castle","metadata":{"id":"driven-castle"},"source":["And compute the total growth during the interval."]},{"cell_type":"code","execution_count":null,"id":"prescription-optics","metadata":{"id":"prescription-optics"},"outputs":[],"source":["total_growth = p_end - p_0\n","total_growth"]},{"cell_type":"markdown","id":"accepted-auditor","metadata":{"id":"accepted-auditor"},"source":["Finally, we can compute average annual growth."]},{"cell_type":"code","execution_count":null,"id":"convertible-patch","metadata":{"id":"convertible-patch"},"outputs":[],"source":["annual_growth = total_growth / elapsed_time\n","annual_growth"]},{"cell_type":"markdown","id":"japanese-merit","metadata":{"id":"japanese-merit"},"source":["From 1950 to 2016, world population grew by about 0.07 billion people per year, on average.\n","\n","<br>\n","\n","‚úÖ Active Reading: What is the disadvantage of including an actual value like \"1950\" or \"0.0722\" in our code (as opposed to creating a variable)?"]},{"cell_type":"markdown","source":["\n","Now we want to create a new `Series` that represents our linear model--this will be our fitted linear curve, and we can then compare it to our data.  We'll start with `p_0`,\n","and then add `annual_growth` each year. To store the results, we'll use a\n","`Series` object:"],"metadata":{"id":"8tKpOFgZvsQA"},"id":"8tKpOFgZvsQA"},{"cell_type":"code","execution_count":null,"id":"duplicate-leave","metadata":{"id":"duplicate-leave"},"outputs":[],"source":["results = pd.Series([],dtype=object)\n","results.name = 'Population'\n","results.index.name = 'Year'"]},{"cell_type":"markdown","id":"expired-salmon","metadata":{"id":"expired-salmon"},"source":["In this example, the index and values of the `Series` are given as `Year` and `Population` to give names to the index and the values.  These names don't affect the computation, but they appear when we display or plot the `Series`.  We can set the first value in the new `Series` like this."]},{"cell_type":"code","execution_count":null,"id":"convenient-thong","metadata":{"id":"convenient-thong"},"outputs":[],"source":["results[t_0] = p_0"]},{"cell_type":"markdown","id":"constant-casino","metadata":{"id":"constant-casino"},"source":["Here's what it looks like so far."]},{"cell_type":"code","execution_count":null,"id":"israeli-surveillance","metadata":{"id":"israeli-surveillance"},"outputs":[],"source":["pd.DataFrame(results)"]},{"cell_type":"markdown","id":"stretch-snapshot","metadata":{"id":"stretch-snapshot"},"source":["Now we set the rest of the values by simulating annual growth.  The `change_func` here is simply adding the annual growth every year.  For this reason, this linear model is sometimes called a *constant growth model*."]},{"cell_type":"code","execution_count":null,"id":"attended-morris","metadata":{"id":"attended-morris"},"outputs":[],"source":["for t in range(t_0, t_end):\n","    results[t+1] = results[t] + annual_growth"]},{"cell_type":"markdown","id":"signed-colleague","metadata":{"id":"signed-colleague"},"source":["Notice:\n","\n","* In a loop defined by `range`, the values of `t` go from from `t_0` to `t_end`; but while the first value is include (`t_0`) in the loop, the last one (`t_end`) is not.\n","\n","* Inside the loop, we compute the population for the next year by adding the population for the current year and `annual_growth`. \n","\n","* Since `t_end = 2016`, in the last time through the loop, the value of `t` is 2015, so the last label in `results` is 2016.\n","\n","Here's what the results look like, compared to the estimates."]},{"cell_type":"code","execution_count":null,"id":"wrong-brooks","metadata":{"id":"wrong-brooks"},"outputs":[],"source":["results.plot(color='gray', label='Model',title='Constant Growth Model',\n","            legend=True)\n","plot_estimates()"]},{"cell_type":"markdown","id":"automated-albany","metadata":{"id":"automated-albany"},"source":["From 1950 to 1990, the model does not fit the data particularly well, but after that, it's OK."]},{"cell_type":"markdown","id":"tender-summer","metadata":{"id":"tender-summer"},"source":["### Is the model correct?: Quantifying error\n","\n","We've created a model here and tried to fit our model to the data.   How do we determine whether it is a good model?  "]},{"cell_type":"markdown","id":"frozen-scotland","metadata":{"id":"frozen-scotland"},"source":["One way to characterize the \"fit\" of a model is *absolute error*, which is the absolute value of the difference between points in the original data and the points in our linear model.\n","\n","<br>\n","\n","To compute absolute error, we want to find the absolute value of the difference between each point in the two `Series`.  We can use the NumPy function `abs` and simple subtraction to find this value for each year:"]},{"cell_type":"code","execution_count":null,"id":"caring-garlic","metadata":{"id":"caring-garlic"},"outputs":[],"source":["from numpy import abs\n","abs_error = abs(census - results)\n","abs_error.tail()"]},{"cell_type":"markdown","id":"bridal-extraction","metadata":{"id":"bridal-extraction"},"source":["When you subtract two `Series` objects, the result is a new `Series`.\n","\n","‚úÖ Active Reading: Why is the difference for 2016 so tiny?"]},{"cell_type":"markdown","source":["Because the result is a `Series`, we can plot it without much trouble:"],"metadata":{"id":"r0bj_6ByzO2T"},"id":"r0bj_6ByzO2T"},{"cell_type":"code","source":["abs_error.plot(color='blue', ylabel = 'Error (Billions)', label='Absolute Error',title='Absolute Error',\n","            legend=True);"],"metadata":{"id":"4BYkYsz9zZGY"},"id":"4BYkYsz9zZGY","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can use other NumPy functions to help us understand the data in this `Series`.  For instance, to summarize the results, we can compute the *mean absolute error* and *maximum absolute error*:"],"metadata":{"id":"-r1yyq-nyi8U"},"id":"-r1yyq-nyi8U"},{"cell_type":"code","execution_count":null,"id":"corresponding-emerald","metadata":{"id":"corresponding-emerald"},"outputs":[],"source":["from numpy import mean\n","from numpy import max\n","\n","mean_abs = mean(abs_error)\n","max_abs = max(abs_error)\n","print(\"The average error is \", mean_abs, \"billion people,\")\n","print(\"while the maximum error is \", max_abs, \" billion people.\")"]},{"cell_type":"markdown","id":"composite-partnership","metadata":{"id":"composite-partnership"},"source":["On average, the model was off by about 0.16 billion people, and in the worst case, it was off by about 0.3 billion.  0.3 billion is a lot of people, so that might sound like a serious discrepancy.\n","But counting everyone is the world is hard, and we should not expect the estimates to be exact: it's still hard to tell if this is a significant error!\n","\n","<br>\n","\n","This is where *relative error* is helpful.  Relative error is the *percentage* difference between the values in the two `Series`.  To find this, we divide the absolute error by the estimates themselves and multiply by 100:"]},{"cell_type":"code","execution_count":null,"id":"advisory-complex","metadata":{"scrolled":true,"id":"advisory-complex"},"outputs":[],"source":["rel_error = (abs_error / census) * 100"]},{"cell_type":"markdown","source":["Now let's check out the results:"],"metadata":{"id":"DblwV84X2a2q"},"id":"DblwV84X2a2q"},{"cell_type":"code","source":["rel_error.plot(color='green', ylabel = 'Error (%)', label='Relative Error',title='Relative Error',\n","            legend=True);\n","mean_rel = mean(rel_error)\n","max_rel = max(rel_error)\n","print(\"The average error is \", mean_rel, \"percent, while the maximum error is \", max_rel, \" percent.\")\n","print(\"   \")"],"metadata":{"id":"ucGcY4ox1nMe"},"id":"ucGcY4ox1nMe","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"greater-register","metadata":{"id":"greater-register"},"source":["Whoa!  9% is a pretty significant error.  And notice that it's a lot easier to understand the importance of this number than the raw absolute error.  I think we're going to have to iterate our model (what a surprise! üòè ).\n","\n","You might wonder why we divided by `census` rather than `results`.\n","In general, if you think one data set is more accurate than the other, you put the better one in the denominator.  Here we have actual data vs. a model of that data, so we will assume that the data is more accurate.\n","\n","<br>\n","\n","---"]},{"cell_type":"markdown","id":"unnecessary-million","metadata":{"id":"unnecessary-million"},"source":["## Summary\n","\n","This chapter is a first step toward modeling changes in world population growth during the last 70 years.\n","\n","* We used Pandas to read data from a web page and store the results in a `DataFrame`.\n","\n","* Then we computed average population growth and used it to build a simple model with constant annual growth.\n","\n","* We compared our model to the known data by  finding the absolute and relative error between the model and the known census data.\n"]},{"cell_type":"markdown","id":"advanced-ivory","metadata":{"id":"advanced-ivory"},"source":["## Exercises"]},{"cell_type":"markdown","id":"hearing-today","metadata":{"tags":[],"id":"hearing-today"},"source":["Here's the code from this chapter all in one place."]},{"cell_type":"code","execution_count":null,"id":"terminal-reynolds","metadata":{"tags":[],"id":"terminal-reynolds"},"outputs":[],"source":["t_0 = census.index[0]\n","t_end = census.index[-1]\n","elapsed_time = t_end - t_0\n","\n","p_0 = census[t_0]\n","p_end = census[t_end]\n","\n","total_growth = p_end - p_0\n","annual_growth = total_growth / elapsed_time\n","\n","results = pd.Series([],dtype=object)\n","results[t_0] = p_0\n","\n","for t in range(t_0, t_end):\n","    results[t+1] = results[t] + annual_growth"]},{"cell_type":"code","execution_count":null,"id":"organizational-memphis","metadata":{"tags":[],"id":"organizational-memphis"},"outputs":[],"source":["results.plot(color='gray', label='Model',title='Constant Growth Model',\n","            legend=True)\n","plot_estimates()"]},{"cell_type":"markdown","id":"ecological-welsh","metadata":{"id":"ecological-welsh"},"source":["### Exercise 1\n","\n","‚úÖ\n","  Clearly the population data is not really linear.  But by observation, we can see that see that the data seems to be roughly linear from about 1970 to present.  Let's see if we can use that data to get a better fit.  Try fitting the linear model using data from 1970 to the present, and see if that does a better job.\n","\n","Suggestions: \n","\n","1. Define the growth constant by looking at data between 1970 and the present.  In other words, define `t_1` to be 1970 (i.e. `t1 = census.index[20]` and `p_1` to be the population in 1970.  Use `t_1` and `p_1` to compute annual growth.\n","\n","2. When you create the simulation, start with the 1950 data: use `t_0` and `p_0` to run the simulation. \n"]},{"cell_type":"code","execution_count":null,"id":"rising-anger","metadata":{"id":"rising-anger"},"outputs":[],"source":["# Compute the growth constant: average annual growth from 1970 to 2016\n","# Follow the same process we used above, but use different t_1 and p_1 as \n","# explained above\n","\n"]},{"cell_type":"code","execution_count":null,"id":"false-handbook","metadata":{"id":"false-handbook"},"outputs":[],"source":["# Store model results from 1950 to the present in Series called 'results'\n","# The process will be similar to the one used in this notebook\n"]},{"cell_type":"code","execution_count":null,"id":"political-loading","metadata":{"id":"political-loading"},"outputs":[],"source":["# Plot results vs. actual data\n"]},{"cell_type":"markdown","source":["### Exercise 2\n","\n","So we now have a plot that matches the slope from 1970 to present well, but our starting point in 1950 means that our curve is far off the actual data.  We now want to \"shift\" our curve downward to produce a much smaller relative error."],"metadata":{"id":"t11OCaqsXHUB"},"id":"t11OCaqsXHUB"},{"cell_type":"code","source":["# Change the shift constant to improve the match between the\n","# model and the data.  Change this constant, run this cell, and \n","# then rerun your plot\n","shift_constant = 0.0\n","\n","# This subtracts the shift constant from each data point in the model\n","# Note: be careful running this cell.  If you run it twice without \n","# rerunning your results above this, you will subtract from the results\n","# twice\n","results = results - shift_constant"],"metadata":{"id":"QGvdmZwN6rMs"},"id":"QGvdmZwN6rMs","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Determine the relative error between the model and the census data\n"],"metadata":{"id":"YsUYe-837Rs4"},"id":"YsUYe-837Rs4","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Exercise 3\n","\n","‚úÖ\n","Explore the model you built in Exercise 1 until you find the `shift_constant` that creates the smallest average relative error.  Then answer these questions:\n","\n","* What is the best shift constant?  \n","* If things went well, you were able to get the average error down to 2% or even less.  This seems OK, right?  However, we're trying to understand population growth.   Even if a linear model fits the data, what about the nature of population growth makes it unlikely that a linear model would be accurate in the long haul?  Use your intuition to think about what kind of growth you might expect for a population."],"metadata":{"id":"cUbqg_eC84TV"},"id":"cUbqg_eC84TV"}],"metadata":{"celltoolbar":"Tags","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"collapsed_sections":["unnecessary-million"]}},"nbformat":4,"nbformat_minor":5}