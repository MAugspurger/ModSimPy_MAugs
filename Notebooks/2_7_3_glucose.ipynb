{"cells":[{"cell_type":"markdown","metadata":{"id":"DxqNr2KFxEwM"},"source":["# 2.7.3 The Glucose Minimal Model (Fitting Parameters)"]},{"cell_type":"markdown","metadata":{"id":"XgWpVe42xEwS"},"source":["*Modeling and Simulation in Python*\n","\n","Copyright 2021 Allen Downey, (License: [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/))\n","\n","Revised, Mike Augspurger (2021-present)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"B0kEyZH5xEwU"},"outputs":[],"source":["#@title\n","# Import necessary libraries\n","from os.path import basename, exists\n","from os import mkdir\n","\n","def download(url,folder):\n","    filename = folder + basename(url)\n","    if not exists(folder):\n","        mkdir(folder)\n","    # fetches the file at the given url if it is not already present\n","    if not exists(filename):\n","        from urllib.request import urlretrieve\n","        local, _ = urlretrieve(url, filename)\n","        print('Downloaded ' + local)\n","\n","download('https://github.com/MAugspurger/ModSimPy_MAugs/raw/main/Notebooks/'\n","        + 'ModSimPy_Functions/modsim.py', 'ModSimPy_Functions/')\n","download('https://github.com/MAugspurger/ModSimPy_MAugs/raw/main/Notebooks/'\n","        + 'ModSimPy_Functions/chap06.py', 'ModSimPy_Functions/')\n","\n","from ModSimPy_Functions.modsim import *\n","from ModSimPy_Functions.chap06 import *\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"U4o2fmLDxEwW"},"source":["In the class, we investigated the effect that the parameters ($k_1, k_2, etc...$ had our model, and discovered it was significant.  But how do we actually choose the parameters so that our model matches the data?\n","\n","<br>\n","\n","In this notebook, we'll use a well-known method to do just that."]},{"cell_type":"markdown","source":["## The Least Squares Method\n","\n","Earlier in the course, we fit linear and exponential curves to our world population data by the guess-and-check method: guess at a slope, say, and then check to see how close it matches the data.  We could do the same here.  But with 4 parameters that gets very difficult, and we would never know if we've found the best set of parameters.  \n","\n","<br>\n","\n","So we'll use an algorithm to help us out: a SciPy function called `leastsq`, which stands for \"least squares\".  A least squares algorithm finds parameters by minimizing the sum of squared differences between the results of the model and the known data points.  The \"squaring\" serves two purposes: \n","\n","<br>\n","\n","* it eliminates the possibility that a negative error might cancel out a positive error\n","* it heavily penalizes a data point that has a large error.\n","\n","<br>\n","\n","The sum of the squared errors becomes the *metric* we use to evaluate a set of parameters.  We can then minimize this metric to find the best parameters."],"metadata":{"id":"23xnusWdwh8z"}},{"cell_type":"markdown","metadata":{"id":"uc_j9ZrKxEwX"},"source":["### Computing errors\n","\n","Before we can minimize the error, though, we need a way to compute it.  To do this, we'll evaluate our model at each time step where we have known data, and then find the difference between the model and the known data at that time step.  In the end, we'll have a Series that contains the error at of these time steps.\n","\n","<br>\n","\n","To begin, we'll import our data and create a system, using the parameters and the `make_system` function from the previous notebook:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lR1wBmw1xEwY"},"outputs":[],"source":["filename = 'https://github.com/MAugspurger/ModSimPy_MAugs/raw/main/Images_and_Data/Data/glucose_insulin.csv'\n","# If you are using this notebook offline, you will need to upload this data\n","# from the Images_and_Data folder.  Comment out the line above, and uncomment the\n","# line below this one, and run this cell\n","# filename = '../Images_and_Data/Data/glucose_insulin.csv'\n","data = pd.read_csv(filename, index_col='time')"]},{"cell_type":"markdown","source":["Because of the way `leastsq()` is set up, we'll need to rework `make_system` so that it imports the parameters as a \"tuple\": a foundational Python object that is simply a list of objects.  Notice we also no longer need a `state` object, since `run_solve_ivp` takes care of that:"],"metadata":{"id":"4htVQ0DD49OB"}},{"cell_type":"code","source":["def make_system(params, data):\n","    G0, k1, k2, k3, dt = params\n","    t_0 = data.index[0]\n","    t_end = data.index[-1]\n","    \n","    Gb = data.glucose[t_0]\n","    Ib = data.insulin[t_0]\n","    \n","    I = interp1d(data.insulin.index,data.insulin.values)\n","\n","    init = pd.Series(dict(G=G0, X=0),dtype=np.float64)\n","    system = dict(init=init,\n","                  k1=k1,k2=k2,\n","                  k3=k3,dt=dt,\n","                  Gb=Gb, Ib=Ib, I=I,\n","                  t_0=t_0, t_end=t_end)\n","    \n","    return system\n","\n","G0 = 270.0\n","k1 = 0.02\n","k2 = 0.02\n","k3 = 1.5e-05\n","dt = 2\n","params = G0, k1, k2, k3, dt\n","system = make_system(params,data)\n"],"metadata":{"id":"_DirmuzS43oI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TrSqORqDxEwb"},"source":["Now we'll run the initial value problem solver."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ilIvZW4xEwc"},"outputs":[],"source":["results, details = run_solve_ivp(system, slope_func, \n","                                 t_eval=data.index)\n","details.message"]},{"cell_type":"markdown","metadata":{"id":"JFpmYkNjxEwe"},"source":["Because we specify `t_eval=data.index`, the results are evaluated at the same time stamps as the data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6MDGHjkxEwe"},"outputs":[],"source":["results.tail()"]},{"cell_type":"markdown","metadata":{"id":"BKtyOvf4xEwf"},"source":["We can plot the results like this."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BuiyRfxpxEwf"},"outputs":[],"source":["data.glucose.plot(style='o', alpha=0.5, label='data',\n","                  legend=True)\n","results.G.plot(style='-', color='C0', label='model',\n","               xlabel='Time (min)',\n","               ylabel='Concentration (mg/dL)',\n","              legend=True);"]},{"cell_type":"markdown","metadata":{"id":"wVyhNtToxEwg"},"source":["We can compute the errors by subtracting one data set from the other (this is why it was important that our results be evaluated at the same time steps as our data: otherwise, we couldn't add or subtract them):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TRjeQjYQxEwg"},"outputs":[],"source":["errors = results.G - data.glucose\n","pd.DataFrame(errors)"]},{"cell_type":"markdown","metadata":{"id":"NwaF6pSKxEwh"},"source":["Most of the errors are under $10 mg/dL$.  But notice that during the first three time steps, the model does not fit the data. This is not surprising.  If you remember, the concentration of glucose in the blood stream initially varies widely (very high near the injection point, for inistance).  That's hard to capture it one number.  But as the glucose disperses in the blood stream, our model matches pretty well."]},{"cell_type":"markdown","source":["✅ Active reading: Explain in your own words why the first three data points in the model are not very accurate.  Considering that the errors are squared in the least squares method, what would these data points do to our \"sum\" of squared errors?\n","\n","✅ ✅ Answer here."],"metadata":{"id":"5VGMLnel2k_q"}},{"cell_type":"markdown","metadata":{"id":"-mSb2TLgxEwh"},"source":["### Defining an Error Function\n","\n","Remember that when we used `root_scalar`, we defined an error function that calculated how close the final temperature of our model coffee was to our known experimental value of 70 degrees.\n","\n","<br>\n","\n","We are going to do the same thing here, but now we want the error func to return an array of errors (i.e. that does exactly what we did in the previous section).  `leastsq` will then run our model while changing the paramters, trying to make the sum of this array equal to zero.\n","\n","<br>\n","\n","Here's the error function that does this:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCAP5D2rxEwi"},"outputs":[],"source":["def error_func(params,data):\n","    \"\"\"Computes an array of errors to be minimized.\n","    \n","    params: \n","    data: \n","    returns: \n","    \"\"\"\n","\n","    print(params)\n","    system = make_system(params, data)\n","    \n","    results, details = run_solve_ivp(system, slope_func, \n","                                     t_eval=data.index)\n","    \n","    errors = results.G - data.glucose\n","    return errors.iloc[3:]"]},{"cell_type":"markdown","metadata":{"id":"Duqs6ffNxEwj"},"source":["`error_func` uses the given parameters to make a `System` object, runs the simulation, and returns the errors.\n","\n","<br>\n","\n","But notice that it does not return all of the errors; rather, it uses the \"index location\" tool `iloc` to select only the elements with index 3 or more. In other words, it omits the elements with index 0, 1, and 2: the first three data points with large errors.  Since we don't expect the model to fit the data in this region, and since the errors in that region would overwhelm the errors elsewhere, we'll leave them out.\n","\n","<br>\n","\n","We can call `error_func` like this:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4JLEyK78xEwj"},"outputs":[],"source":["errors = error_func(params, data)\n","errors.head()"]},{"cell_type":"markdown","source":["✅ ✅ Active reading: Add inline comments (#) to `error_function`, and explain what params, data, and return are in the docstring at the top of the function."],"metadata":{"id":"hXy4w3Vn-gS7"}},{"cell_type":"markdown","metadata":{"id":"wABctPgvxEwk"},"source":["### Running `leastsq`\n","\n","Now we're ready to call `leastsq`.  As arguments, we pass `error_func`, the parameters where we want to start the search (this is why we had to change `make_system` to include `params`), and the data, which will be passed as an argument to `error_func`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vL7w4NWxxEwk"},"outputs":[],"source":["best_params, fit_details = leastsq(error_func, params, data)"]},{"cell_type":"markdown","metadata":{"id":"JlI-RMN8xEwl"},"source":["Each time `error_func` is called, it prints the parameters, so we can get a sense of how `leastsq` works.   Look at one of the printed columns: do you see how it starts at the given value (say, 270 for G0) and then starts to change?   Each line represents another \"guess\" by the `leastsq` algorithm, and with each guess, it searches out a smaller sum of the squares of the errors.  This process is called *iteration*.\n","\n","<br>\n","\n","Notice that in the last few iterations, the values of the parameters are changing by miniscule amounts: at this point, the algorithm is narrowing down the values to its final answer, which is the set of parameters that minimize the sum of the squares of the errors.\n","\n","<br>\n","\n","`leastsq` has two return values.  The first is an array with the best parameters:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6uUrzYCuxEwl"},"outputs":[],"source":["best_params"]},{"cell_type":"markdown","metadata":{"id":"IGqxif7KxEwl"},"source":["The second is an object with information about the results, including a success flag and a message."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pEr5-GSdxEwm"},"outputs":[],"source":["fit_details.success"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JhHzu8QkxEwo"},"outputs":[],"source":["fit_details.mesg"]},{"cell_type":"markdown","metadata":{"id":"BJ8hoe8txEwp"},"source":["This means that the last two iterations produced nearly identical results, and is a sign that the iteration process is complete."]},{"cell_type":"markdown","source":["### Checking our Results\n","\n","Now that we have `best_params`, we can use it to make a `System` object, run the simulation, and see how accurate our results are."],"metadata":{"id":"NeDQXS3V_Lwr"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"AKZYZQBrxEwp"},"outputs":[],"source":["system2 = make_system(best_params, data)\n","results2, details = run_solve_ivp(system2, slope_func, t_eval=data.index)\n","print(details.message)\n","data.glucose.plot(style='o', alpha=0.5, label='data',\n","                 legend=True)\n","results.G.plot(style='-', color='C0', label='model',\n","               xlabel='Time (min)',\n","               ylabel='Concentration (mg/dL)',\n","              legend=True);\n"]},{"cell_type":"markdown","metadata":{"id":"QCeVhRo-xEwq"},"source":["Now we can compute the errors directly.  What kind of value do we expect?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0MaWI09NxEwr"},"outputs":[],"source":["errors2 = results2.G - data.glucose\n","errors2.head()"]},{"cell_type":"markdown","metadata":{"id":"RZ5rKlB6xEwr"},"source":["Notice that the errors are not zero.  This is because no function of the form that we are using is capable of going through each data point.  The curve is a \"best fit\", but it is not a *perfect* fit.  \n","\n","<br>\n","\n","Let's compare the error resulting from our initial parameters to the error resulting from the `best_params`.   To do this, we want to sum the square of these errors, a process that usually happens *within* the function `leastsq`.   Here are the results:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ljA-Xe81xEws"},"outputs":[],"source":["from numpy import sum\n","\n","init_param_error = sum(errors.iloc[3:]**2)\n","best_param_error = sum(errors2.iloc[3:]**2)\n","print(\"The sum of squared errors for the initial params is\", round(init_param_error,1))\n","print(\"The sum of squared errors for the best params is\", round(best_param_error,1))"]},{"cell_type":"markdown","metadata":{"id":"YMb0jsjSxEws"},"source":["The absolute size of these numbers is not meaningful: if we had used more time steps, the magnitude of the numbers would be larger.   But we can see that the sum of the squares went down noticeably, and could calculate a percent change:"]},{"cell_type":"code","source":["rel_change_error = (init_param_error-best_param_error)/init_param_error\n","print(\"The size of the sum of squares of the error decreased by\", \n","      round(rel_change_error*100,1), \"percent\")"],"metadata":{"id":"KXppZI6zA7sQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","<br>\n","\n","## Summary\n","\n","In this notebook we tested out the least squares method, an algorithm that helped us to minimize the difference between our model and our known data (i.e. the error of the model).   \n","\n","<br>\n","\n","Having validated our parameters by comparing our results to known data, we would be more confident predicting the behavior of the system when one of the conditions of the physical system (like the initial condition) changed.\n","\n","<br>\n","\n","---"],"metadata":{"id":"YsWKamSwBz2u"}},{"cell_type":"markdown","metadata":{"id":"YAHJSa9BxEwt"},"source":["### Exercise 1\n","\n","How sensitive are the results to the starting guess for the parameters?  \n","\n","<br>\n","\n","Let's see what difference the initial value of G0 makes on the final results.  Run the notebook 3 times, and each time take note of the plot of results, the optimized value for G0, and sum of squared errors produced with the optimized parameters (the variable called `best_param_errors'):\n","\n","<br>\n","\n","* First, run it with the values we have been using all along ($G0 = 270$).\n","* Next, change G0 just by a bit and run the notebook ($G0 = 300$ rather than $270$).   \n","* Finally, change G0 by a lot (say $G0 = 800$).  \n","\n","<br>\n","\n","What happens to the recommended G0 value and overall error (i.e. the sum of squared errors) in each case?\n","\n","<br>\n","\n","Hint: you test a new set of parameters simply by changing the parameters at the top of the notebook, and running all the cells again."]},{"cell_type":"markdown","metadata":{"id":"LvKK7t3nxEwt"},"source":["✅ ✅  Describe your results (with numbers!) and try to explain why this might happen.  What does this suggest about algorithms like `leastsq`?  Can you always trust them?\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}